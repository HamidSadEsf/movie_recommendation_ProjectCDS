{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "961f1553",
   "metadata": {},
   "source": [
    "# Importing libraries and datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "30df1cd7-e68b-44ba-b763-a32eb448b9cc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from scipy.sparse import csr_matrix, save_npz\n",
    "from sklearn import neighbors\n",
    "from sklearn.cluster import KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "acaa5c7f-8388-45ea-afaa-bd0525b0cff8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "ParserError",
     "evalue": "Error tokenizing data. C error: Calling read(nbytes) on source failed. Try engine='python'.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mParserError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m genome_scores \u001b[38;5;241m=\u001b[39m  pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdata/genome-scores.csv\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      3\u001b[0m movies \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdata/movies.csv\u001b[39m\u001b[38;5;124m'\u001b[39m,  usecols \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmovieId\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m----> 4\u001b[0m ratings \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdata/ratings.csv\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43musecols\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmovieId\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43muserId\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrating\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/pandas/util/_decorators.py:211\u001b[0m, in \u001b[0;36mdeprecate_kwarg.<locals>._deprecate_kwarg.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    209\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    210\u001b[0m         kwargs[new_arg_name] \u001b[38;5;241m=\u001b[39m new_arg_value\n\u001b[0;32m--> 211\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/pandas/util/_decorators.py:331\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    325\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m num_allow_args:\n\u001b[1;32m    326\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m    327\u001b[0m         msg\u001b[38;5;241m.\u001b[39mformat(arguments\u001b[38;5;241m=\u001b[39m_format_argument_list(allow_args)),\n\u001b[1;32m    328\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[1;32m    329\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mfind_stack_level(),\n\u001b[1;32m    330\u001b[0m     )\n\u001b[0;32m--> 331\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/pandas/io/parsers/readers.py:950\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    935\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m    936\u001b[0m     dialect,\n\u001b[1;32m    937\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    946\u001b[0m     defaults\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdelimiter\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m\"\u001b[39m},\n\u001b[1;32m    947\u001b[0m )\n\u001b[1;32m    948\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m--> 950\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/pandas/io/parsers/readers.py:611\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    608\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n\u001b[1;32m    610\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m parser:\n\u001b[0;32m--> 611\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mparser\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnrows\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/pandas/io/parsers/readers.py:1778\u001b[0m, in \u001b[0;36mTextFileReader.read\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m   1771\u001b[0m nrows \u001b[38;5;241m=\u001b[39m validate_integer(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnrows\u001b[39m\u001b[38;5;124m\"\u001b[39m, nrows)\n\u001b[1;32m   1772\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1773\u001b[0m     \u001b[38;5;66;03m# error: \"ParserBase\" has no attribute \"read\"\u001b[39;00m\n\u001b[1;32m   1774\u001b[0m     (\n\u001b[1;32m   1775\u001b[0m         index,\n\u001b[1;32m   1776\u001b[0m         columns,\n\u001b[1;32m   1777\u001b[0m         col_dict,\n\u001b[0;32m-> 1778\u001b[0m     ) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[attr-defined]\u001b[39;49;00m\n\u001b[1;32m   1779\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnrows\u001b[49m\n\u001b[1;32m   1780\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1781\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[1;32m   1782\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclose()\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/pandas/io/parsers/c_parser_wrapper.py:230\u001b[0m, in \u001b[0;36mCParserWrapper.read\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m    228\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    229\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlow_memory:\n\u001b[0;32m--> 230\u001b[0m         chunks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_reader\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_low_memory\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnrows\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    231\u001b[0m         \u001b[38;5;66;03m# destructive to chunks\u001b[39;00m\n\u001b[1;32m    232\u001b[0m         data \u001b[38;5;241m=\u001b[39m _concatenate_chunks(chunks)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/pandas/_libs/parsers.pyx:808\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader.read_low_memory\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/pandas/_libs/parsers.pyx:866\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader._read_rows\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/pandas/_libs/parsers.pyx:852\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader._tokenize_rows\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/pandas/_libs/parsers.pyx:1973\u001b[0m, in \u001b[0;36mpandas._libs.parsers.raise_parser_error\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mParserError\u001b[0m: Error tokenizing data. C error: Calling read(nbytes) on source failed. Try engine='python'."
     ]
    }
   ],
   "source": [
    "# import datasets:\n",
    "genome_scores =  pd.read_csv('data/genome-scores.csv')\n",
    "movies = pd.read_csv('data/movies.csv',  usecols = [\"movieId\"])\n",
    "ratings = pd.read_csv('data/ratings.csv', usecols = [\"movieId\", \"userId\", \"rating\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0eb4b1b1",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "043c9e43-4eab-46a5-84c6-29ddf48b4be3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Count movies in the movies df\n",
    "tmm = movies[\"movieId\"].nunique()\n",
    "# Count movies in the matings df\n",
    "tmr = ratings[\"movieId\"].nunique()\n",
    "# Count movies in the genome_score df\n",
    "tmg = genome_scores[\"movieId\"].nunique()\n",
    "print(\"The total number of movies in movies, ratings and genome score dataframes, respectively :\", tmm, tmr, tmg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27cfdb71-5faa-4abe-9e7f-51baa61c21d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a movie - user - rating data frame with movies present in all the dataframes\n",
    "tagged_movies = pd.DataFrame(genome_scores['movieId'].value_counts()).index\n",
    "mov_rat = pd.merge(movies, ratings, on=\"movieId\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4afa696-bcfe-40a2-9b29-9bbcbeea1fd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df = mov_rat[mov_rat[\"movieId\"].isin(tagged_movies)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cabd79df-a933-4c98-9d60-f0fb9bff7444",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Reducing the dataframe by removing unpopular movies and anactive \n",
    "#Shringking movies\n",
    "gf = pd.DataFrame(final_df['movieId'].value_counts())\n",
    "rare_movies = gf[gf['movieId'] <= 1000].index\n",
    "final_df = final_df[~final_df[\"movieId\"].isin(rare_movies)]\n",
    "print('Out of total of ', gf.shape[0] , ' movies, ', rare_movies.shape[0], ' are considered rare and will be removed.')\n",
    "print('The final number of movies is ', final_df[\"movieId\"].nunique())\n",
    "\n",
    "#Shringking users\n",
    "udf = pd.DataFrame(final_df['userId'].value_counts())\n",
    "lazy_users = udf[udf['userId'] <= 500].index\n",
    "final_df = final_df[~final_df[\"userId\"].isin(lazy_users)]\n",
    "print('Out of total of ', udf.shape[0] , ' users, ', lazy_users.shape[0], ' are considered lazy and will be removed.')\n",
    "print('The final number of users is ', final_df[\"userId\"].nunique())\n",
    "\n",
    "# Create the user->movie sparse rating matrix. Fill the NA with zeros\n",
    "pivot = final_df.pivot_table(index=\"userId\", columns=\"movieId\", values=\"rating\")\n",
    "pivot.fillna(0,inplace=True)\n",
    "\n",
    "#Estimate sparsity\n",
    "sparsity = 1.0 - ( np.count_nonzero(pivot) / float(pivot.size) )\n",
    "print(\"The resulting sparcity of the matrix is:\", sparsity)\n",
    "\n",
    "#Create non-sparce dataset\n",
    "csr_data = csr_matrix(pivot.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e28261c-01b1-4f4c-bb6c-fc8a641edcc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df.to_csv('matrices/user_movie_rating.csv', index=False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a905a2b-f8e8-4dba-b243-fcd74fb8c7a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "pivot.to_csv('matrices/pivot.csv', index=True, header=\"userId\") /mat "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9660bae4-e789-496f-8826-68fab00b36cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_npz(\"matrices/sparse_ratings.npz\", csr_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9663b060",
   "metadata": {},
   "source": [
    "# Modelling\n",
    "Below we execute the following steps:\n",
    "* Randomly choosing a target user fo whom recommendations will be generated\n",
    "* Pre-clustering of users using KMeans model\n",
    "* Creating a new matrix corresponding with users in the target user cluster\n",
    "* Defining the Mean User Vector for the working data matrix\n",
    "* Training the Nearest Neighbors model on the Mean User Vector\n",
    "* Processing the results of the NN modeling: collecting, aggregating, filtering results and presenting recommendations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c3115bd",
   "metadata": {},
   "source": [
    "## Pre-clustering with KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1c154f9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Pre-clustering users with K-means\n",
    "# 20 clusters\n",
    "kmeans = KMeans(n_clusters=20, algorithm='lloyd', n_init='auto').fit(csr_data) # Demands lots of resources\n",
    "labels = kmeans.labels_ \n",
    "unique, counts = np.unique(labels, return_counts=True)\n",
    "\n",
    "print(\"The number of users per class:\\n\")\n",
    "for u, c in zip(unique, counts):\n",
    "    print(u, c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abe8a2c5-5e7e-4681-a393-f2e006c8e5d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load sparce crr user-movie utility matrix\n",
    "print(csr_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7768caad",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Let's randomly choose an existing user\n",
    "user_index = np.random.choice(csr_data.shape[0])    \n",
    "print('The target user ', user_index, ' belongs to the cluster number', labels[user_index])\n",
    "\n",
    "# Creating the csr matrix only for usrs of the cluster of the target user\n",
    "# get indices of the users in the selected cluster\n",
    "cluster_user_indices = []\n",
    "for i,l in enumerate(labels):\n",
    "    if l == labels[user_index]:\n",
    "        cluster_user_indices.append(i)\n",
    "        \n",
    "# create a new csr_data only with the users from the cluster\n",
    "mask = np.zeros(csr_data.shape[0], dtype=bool)\n",
    "mask[cluster_user_indices] = True\n",
    "\n",
    "#csr_data_cluster = csr_data[mask]\n",
    "csr_data_cluster = csr_data \n",
    "\n",
    "# When shrinking the matrix, the index of the target user changes to the new_user_index\n",
    "new_user_index = np.nonzero(np.array(cluster_user_indices) == user_index)[0][0]\n",
    "print('The new index of the target user is ', new_user_index)\n",
    "\n",
    "# Calculating the mean users' ratings\n",
    "#def calculate_mean_user_vector(csr_data):\n",
    "#    csr_mean = csr_data.sum(axis=1)/csr_data.getnnz(axis=1)\n",
    "#    mean_user_vector = np.asarray(csr_mean)\n",
    "#    flattened_reshaped = mean_user_vector.mean(axis=1).flatten().reshape(-1, 1)\n",
    "#    return mean_user_vector.reshape(-1), flattened_reshaped\n",
    "\n",
    "#mean_user_vector, model_mean_user_vector = calculate_mean_user_vector(csr_data_cluster)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d29a3804",
   "metadata": {},
   "source": [
    "## Nearest Neighbors model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19f787a9-8f8c-4d0a-bc7f-d55b33d6ff88",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create NN object and fit it with the mean user vector\n",
    "\n",
    "number_of_closest_users = 150\n",
    "nn = neighbors.NearestNeighbors(metric='cosine', algorithm='brute', n_neighbors=number_of_closest_users)\n",
    "nn.fit(csr_data_cluster) \n",
    "number_of_most_closest_users = 20 # for visualization purpose only\n",
    "nn_sub = neighbors.NearestNeighbors(metric='cosine', algorithm='brute', n_neighbors=number_of_most_closest_users)\n",
    "nn_sub.fit(csr_data_cluster)\n",
    "\n",
    "# Find the nearest neighbors for the target user (e.g., User1)\n",
    "\n",
    "mask = np.zeros(csr_data_cluster.shape[0], dtype=bool)\n",
    "mask[new_user_index] = True\n",
    "target_user_row = csr_data_cluster[mask]\n",
    "\n",
    "distances, indices = nn.kneighbors(target_user_row)\n",
    "distances_sub, indices_sub = nn_sub.kneighbors(target_user_row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad651b7e-1eda-4baf-b000-6cc160822278",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Exercise: visualize the results as graph\n",
    "import networkx as nx\n",
    "\n",
    "G = nx.Graph()\n",
    "G.add_node(new_user_index)\n",
    "\n",
    "closest_users = indices.reshape(-1)\n",
    "closest_users_sub = indices.reshape(-1)[1:number_of_most_closest_users +1]\n",
    "closest_users_remaining = indices.reshape(-1)[number_of_most_closest_users+1 :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32d493e1-29f0-4e40-ad98-b96357326ed9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(closest_users), closest_users)\n",
    "print(len(closest_users_sub), closest_users_sub)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbdab375-2195-4bca-b49f-c8e93e0967a4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "G.add_nodes_from(indices.reshape(-1)[1:])\n",
    "\n",
    "weights = 1/(distances.reshape(-1)[1:])\n",
    "\n",
    "G.add_weighted_edges_from(list((new_user_index, n, w) for n,w in zip(closest_users[1:],weights)))\n",
    "\n",
    "pos = nx.fruchterman_reingold_layout(G)\n",
    "\n",
    "plt.figure(figsize = (10, 10))\n",
    "ax = plt.axes()\n",
    "ax.set_facecolor(\"white\")\n",
    "plt.title(\"Visualization of the results of the NN algo\")\n",
    "\n",
    "nx.draw_networkx_nodes(G, pos, node_size = 100, nodelist = closest_users_remaining, node_color = \"#ff5e33\")\n",
    "nx.draw_networkx_nodes(G, pos, node_size = 100, nodelist = closest_users_sub, node_color = \"#33ff83\", label= str(number_of_most_closest_users) + \" closest users\")\n",
    "nx.draw_networkx_nodes(G, pos, node_size = 200, nodelist = [new_user_index], node_color = \"#ffffff\")\n",
    "nxlabels = nx.get_edge_attributes(G,'weight')\n",
    "nx.draw_networkx_edges(G, pos, alpha = 0.3, edge_color = \"#48dbc8\")\n",
    "#nx.draw_networkx_edge_labels(G,pos,edge_labels=nxlabels)\n",
    "#nx.draw_networkx_labels(G,pos,font_size=10, labels={user_index: user_index})\n",
    "nx.draw_networkx_labels(G,pos,font_size=10)\n",
    "plt.grid(visible=False)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83fb115f",
   "metadata": {},
   "source": [
    "## Postprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09a793d5",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9763321",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Collecting ratings from the closers users\n",
    "def keep_rows_csr(mat, indices):\n",
    "    \"\"\"\n",
    "   Keep the rows denoted by ``indices`` form the CSR sparse matrix ``mat``.\n",
    "    \"\"\"\n",
    "    #if not isinstance(mat, scipy.sparse.csr_matrix):\n",
    "     #   raise ValueError(\"works only for CSR format -- use .tocsr() first\")\n",
    "    indices = indices.flatten()\n",
    "    mask = np.zeros(mat.shape[0], dtype=bool)\n",
    "    mask[indices] = True\n",
    "    return mat[mask]\n",
    "    \n",
    "\n",
    "# a csr matrix with the closest users only\n",
    "csr_data_closests_users = keep_rows_csr(csr_data_cluster, indices)\n",
    "\n",
    "# Aggregating the ratings from the closest users\n",
    "# calculate the averaged rating of the movies given by the neiboghrs\n",
    "\n",
    "def closest_users_average_ratings(mat):\n",
    "    mat_array = mat.toarray()\n",
    "    mat_array[mat_array == 0] = np.nan\n",
    "    av_ratings = np.nanmean(mat_array, axis=0)\n",
    "    df = pd.DataFrame(data ={'movieId': , 'rating': av_ratings })\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "rating_aggregation = closest_users_average_ratings(csr_data_closests_users)\n",
    "\n",
    "# rank them by sorting\n",
    "movies_indices_sorted_desc = np.argsort(rating_aggregation)[::-1]\n",
    "best_20_movies = movies_indices_sorted_desc[:20]\n",
    "\n",
    "# Filtering:\n",
    "# get the user movies row\n",
    "mask = np.zeros(csr_data_cluster.shape[0], dtype=bool)\n",
    "mask[new_user_index] = True\n",
    "target_user_row = csr_data_cluster[mask].toarray().flatten()\n",
    "\n",
    "# get indices of the unwatched movies\n",
    "unwatched_indices = np.nonzero(target_user_row == 0)\n",
    "\n",
    "# get indices of the watched movies\n",
    "watched_indices = np.nonzero(target_user_row != 0)\n",
    "\n",
    "# keep only unwatches movie indices\n",
    "filter_arr = []\n",
    "for element in movies_indices_sorted_desc:\n",
    "  if element in unwatched_indices[0]:\n",
    "    filter_arr.append(True)\n",
    "  else:\n",
    "    filter_arr.append(False)\n",
    "\n",
    "movies_to_watch_unfiltered = movies_indices_sorted_desc\n",
    "movies_to_watch = movies_indices_sorted_desc[filter_arr]\n",
    "\n",
    "# Provide personalised recommendations\n",
    "watched_indices = np.nonzero(target_user_row != 0)\n",
    "\n",
    "# get intersection between watched_indices and recommender indices\n",
    "intersection_indices = np.intersect1d(watched_indices[0],best_20_movies[0])\n",
    "\n",
    "print('User watched ', len(watched_indices[0]), ' movies')\n",
    "print('System recommends ', len(best_20_movies), ' movies')\n",
    "print(len(intersection_indices), ' movies are in common')\n",
    "\n",
    "def get_movie_titles_by_indices(indices):\n",
    "    titles = []\n",
    "    for i in indices:\n",
    "        titles.append(pivot.columns[i])\n",
    "    return titles\n",
    "\n",
    "print(\"User \" + str(user_index) + \" watched and rated the following movies:\\n\")\n",
    "\n",
    "for index, movie in enumerate(get_movie_titles_by_indices(watched_indices)[:20]):\n",
    "    print(str(index+1), \":\", str(movie))\n",
    "    \n",
    "print(\"\\n\")\n",
    "print(\"Recommendation for User \" + str(user_index) + \":\\n\")\n",
    "for index, movie in enumerate(get_movie_titles_by_indices(best_20_movies)):\n",
    "    print(str(index+1), \":\", str(movie))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd44dd40-ffd3-40bc-82cb-0881ca7bd98c",
   "metadata": {},
   "outputs": [],
   "source": [
    "var = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "165ec5e8-22e6-43ae-b1b0-e967a19323e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_function(x):\n",
    "    return x + var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8a08619-e865-4aec-a3c8-b5327da304f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(text_function(6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "363dc7b5-fb8a-437c-ad68-1924f85d9a14",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
